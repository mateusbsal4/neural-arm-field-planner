{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2yIEPB068OT",
   "metadata": {
    "id": "f2yIEPB068OT"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pyg/pointnet-classification/02_pointnet_plus_plus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{pyg-pointnet2-train} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a089e90",
   "metadata": {
    "id": "0a089e90"
   },
   "source": [
    "# PointNet++ Model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74844944",
   "metadata": {
    "id": "74844944"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316dcba0",
   "metadata": {
    "id": "316dcba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import random\n",
    "from glob import glob           # ← re-added, in case you use it later\n",
    "from tqdm.auto import tqdm\n",
    " \n",
    "import wandb\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from dataset import GainRegressionDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import PointConv\n",
    "from torch_geometric.nn import MLP, fps, global_max_pool, radius\n",
    "from model import PointNet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5b154",
   "metadata": {
    "id": "46e5b154"
   },
   "source": [
    "## Initialize Weights & Biases\n",
    "\n",
    "We need to call [`wandb.init()`](https://docs.wandb.ai/ref/python/init) once at the beginning of our program to initialize a new job. This creates a new run in W&B and launches a background process to sync data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783f6a3d",
   "metadata": {
    "id": "783f6a3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmateus-salomao\u001b[0m (\u001b[33mmateus-salomao-technical-university-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/geriatronics/pmaf_ws/src/point_net/wandb/run-20250626_182443-ar14hon8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning/runs/ar14hon8' target=\"_blank\">final-experiment/gain-regression</a></strong> to <a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning' target=\"_blank\">https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning/runs/ar14hon8' target=\"_blank\">https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning/runs/ar14hon8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"5e8ac01bfe427d9d4c24a53896514c7eb3fc20e1\"\n",
    "# --- 1) WandB initialization --------------------------------------------\n",
    "wandb_project   = \"point_net_traj_planning\"               #@param {\"type\": \"string\"}\n",
    "wandb_run_name  = \"final-experiment/gain-regression\"  #@param {\"type\": \"string\"}\n",
    "\n",
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    name=wandb_run_name,\n",
    "    job_type=\"baseline-train\"\n",
    ")\n",
    "\n",
    "# --- 2) Fill wandb.config -----------------------------------------------\n",
    "config = wandb.config\n",
    "\n",
    "# (a) Seed & reproducibility\n",
    "config.seed = 4242  #@param {type:\"number\"}\n",
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "\n",
    "# (b) Dataset parameters (replace ModelNet)\n",
    "#     Point to the folder where your PLYs + labels.csv + opt_successfull.yaml live\n",
    "config.data_root     = \"/home/geriatronics/pmaf_ws/src/dataset_generator/data\"  #@param {\"type\":\"string\"}\n",
    "config.labels_csv    = \"labels.csv\"                                        #@param {\"type\":\"string\"}\n",
    "config.success_yaml  = \"opt_successfull.yaml\"                         #@param {\"type\":\"string\"}\n",
    "\n",
    "#     Number of points to sample from each cloud\n",
    "config.npoints       = 2500  #@param {\"type\":\"slider\", min:256, max:4096, step:16}\n",
    "\n",
    "# (c) Split / loader settings\n",
    "config.test_size     = 0.20  #@param {\"type\":\"slider\", min:0.0, max:0.5, step:0.05}\n",
    "config.batch_size    = 16    #@param {\"type\":\"slider\", min:4, max:128, step:4}\n",
    "config.num_workers   = 0     #@param {\"type\":\"slider\", min:1, max:16, step:1}\n",
    "\n",
    "# (d) Device\n",
    "config.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(config.device)\n",
    "\n",
    "# (e) Model/hyperparameters (you can keep these or adjust)\n",
    "config.set_abstraction_ratio_1 = 0.748   #@param {\"type\":\"slider\", min:0.1, max:1.0, step:0.01}\n",
    "config.set_abstraction_radius_1 = 0.4817 #@param {\"type\":\"slider\", min:0.1, max:1.0, step:0.01}\n",
    "config.set_abstraction_ratio_2 = 0.3316   #@param {\"type\":\"slider\", min:0.1, max:1.0, step:0.01}\n",
    "config.set_abstraction_radius_2 = 0.2447 #@param {\"type\":\"slider\", min:0.1, max:1.0, step:0.01}\n",
    "config.dropout                 = 0.1    #@param {\"type\":\"slider\", min:0.0, max:0.5, step:0.05}\n",
    "\n",
    "# (f) Optimizer settings\n",
    "config.learning_rate           = 1e-4  #@param {\"type\":\"number\"}\n",
    "config.epochs                  = 10    #@param {\"type\":\"slider\", min:1, max:100, step:1}\n",
    "config.num_visualization_samples = 20  #@param {\"type\":\"slider\", min:1, max:100, step:1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524732b9",
   "metadata": {
    "id": "524732b9"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "We now load, preprocess and batch the dataset for training, validation/testing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a74c5f",
   "metadata": {
    "id": "12a74c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 224, Val samples: 57\n"
     ]
    }
   ],
   "source": [
    "# Remove pre_transform and transform since GainRegressionDataset handles sampling & normalization internally\n",
    "\n",
    "train_dataset = GainRegressionDataset(\n",
    "    root         = config.data_root,\n",
    "    labels_csv   = config.labels_csv,\n",
    "    success_yaml = config.success_yaml,\n",
    "    split        = \"train\",\n",
    "    test_size     = config.test_size,\n",
    "    random_state = config.seed,\n",
    "    npoints      = config.npoints,\n",
    "    augment      = True\n",
    ")\n",
    "val_dataset = GainRegressionDataset(\n",
    "    root         = config.data_root,\n",
    "    labels_csv   = config.labels_csv,\n",
    "    success_yaml = config.success_yaml,\n",
    "    split        = \"val\",\n",
    "    test_size    = config.test_size,\n",
    "    random_state = config.seed,\n",
    "    npoints      = config.npoints,\n",
    "    augment      = False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size   = config.batch_size,\n",
    "    shuffle      = True,\n",
    "    num_workers  = config.num_workers\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size   = config.batch_size,\n",
    "    shuffle      = False,\n",
    "    num_workers  = config.num_workers\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960beac",
   "metadata": {
    "id": "4960beac"
   },
   "source": [
    "## Implementing the PointNet++ Model using PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973729a2",
   "metadata": {
    "id": "973729a2"
   },
   "source": [
    "## Training PointNet++ and Logging Metrics on Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c524e338",
   "metadata": {
    "id": "c524e338"
   },
   "outputs": [],
   "source": [
    "# Define PointNet++ model.\n",
    "model = PointNet2(\n",
    "    config.set_abstraction_ratio_1,\n",
    "    config.set_abstraction_ratio_2,\n",
    "    config.set_abstraction_radius_1,\n",
    "    config.set_abstraction_radius_2,\n",
    "    config.dropout\n",
    ").to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=config.learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b753e2c0",
   "metadata": {
    "id": "b753e2c0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_step(\n",
    "    epoch):\n",
    "    \"\"\"Training Step for Regression\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        range(num_batches),\n",
    "        desc=f\"Training Epoch {epoch}/{config.epochs}\"\n",
    "    )\n",
    "    data_iter = iter(train_loader)\n",
    "    for _ in progress_bar:\n",
    "        data = next(data_iter).to(device)\n",
    "        # data.pos: [batch_size, npoints, 3]\n",
    "        # data.y  : [batch_size, 36] (regression targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)                   # [batch_size, 36]\n",
    "        #print(f\"Prediction shape: {prediction.shape}\")\n",
    "        #print(f\"Label shape: {data.y.shape}\")\n",
    "        loss = F.mse_loss(prediction, data.y)       # Mean\u2010squared error\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    wandb.log({\n",
    "        \"Train/Loss\": avg_loss,\n",
    "        \"Epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "def val_step(epoch):\n",
    "    \"\"\"Validation Step for Regression\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(val_loader)\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        range(num_batches),\n",
    "        desc=f\"Validation Epoch {epoch}/{config.epochs}\"\n",
    "    )\n",
    "    data_iter = iter(val_loader)\n",
    "    for _ in progress_bar:\n",
    "        data = next(data_iter).to(device)\n",
    "        with torch.no_grad():\n",
    "            prediction = model(data)\n",
    "            loss = F.mse_loss(prediction, data.y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    wandb.log({\n",
    "        \"Validation/Loss\": avg_loss,\n",
    "        \"Epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(epoch):\n",
    "    \"\"\"Save model + optimizer state as a W&B Artifact\"\"\"\n",
    "    ckpt_path = f\"checkpoint_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, ckpt_path)\n",
    "\n",
    "    artifact_name = wandb.util.make_artifact_name_safe(\n",
    "        f\"{wandb.run.name}-{wandb.run.id}-checkpoint\"\n",
    "    )\n",
    "    ckpt_artifact = wandb.Artifact(artifact_name, type=\"checkpoint\")\n",
    "    ckpt_artifact.add_file(ckpt_path)\n",
    "    wandb.log_artifact(ckpt_artifact, aliases=[\"latest\", f\"epoch-{epoch}\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b37a86",
   "metadata": {
    "id": "42b37a86"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab49214869b244429c3828e4d3dab088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8a2e40fb784a9fb45f083bb3e68b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 1/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a799b095154e4c11b555b819d7ede041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92da246e1bd54a05bbf982d4bc438720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 2/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd731a4e3e5046b9a74f50131612da7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4872408782e4b159184a4d20c2cd57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 3/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c19ed99b2cf41ca9443d0efe514d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e12a950b034e55a646394819c6c1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 4/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e84e2f0ce9a41469636d300b3b81eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ec10f7edb54efda579b83a14f6726b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 5/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1e8539a1bd4da28cb0841a4d77a9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731fbc7f49a44c2cb18c0937128d123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 6/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb387e29e55434e978a64d264cea164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f43cc7c0e544109170da3df0973f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 7/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ee81dafb4946f697462db286cfc53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddaaf027c594b918cac94a2c1ca8e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 8/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b8dfc516ba4076b194e4d98baf1866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a9757863cb47629fee8d6b06839cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 9/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc6fc01bef04e1c8aa3db7ae93e6576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10/10:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c42eacadd04c7a9c94c3fdb8c034c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 10/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>  ▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>Train/Loss</td><td>█▃        </td></tr><tr><td>Validation/Loss</td><td>█▄▂       </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train/Loss</td><td>1.5246</td></tr><tr><td>Validation/Loss</td><td>1.35841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final-experiment/gain-regression</strong> at: <a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning/runs/ar14hon8' target=\"_blank\">https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning/runs/ar14hon8</a><br> View project at: <a href='https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning' target=\"_blank\">https://wandb.ai/mateus-salomao-technical-university-of-munich/point_net_traj_planning</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250626_182443-ar14hon8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare an empty W&B Table for visualization\n",
    "viz_table = wandb.Table(\n",
    "    columns=[\n",
    "        \"Epoch\",\n",
    "        \"PointCloud\",\n",
    "        \"Prediction\",\n",
    "        \"GroundTruth\",\n",
    "        \"MSE_Error\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train_step(epoch)\n",
    "    val_step(epoch)\n",
    "   # visualize_evaluation(viz_table, epoch)\n",
    "    save_checkpoint(epoch)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88bbb06a",
   "metadata": {
    "id": "88bbb06a"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236382d",
   "metadata": {
    "id": "e236382d"
   },
   "source": [
    "Next, you can check out the following notebook to learn how to run a hyperparameter sweep on our PointNet++ trainig loop using Weights & Biases:\n",
    "\n",
    "|Tune Hyperparameters using Weights & Biases Sweep|[![](https://colab.research.google.com/assets/colab-badge.svg)](http://wandb.me/pyg-pointnet2-sweep)|"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pointnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}